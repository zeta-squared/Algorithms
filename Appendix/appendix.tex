\subsection*{Resource Models}

When we consider a model for analysing the time complexity of an algorithm, such as the \textbf{\textit{random-access machine (RAM)}} model we need to define a word size of data. Here \textit{word} indicates some object to be stored in data. This topic is important because it creates a limit on how much information can be stored in a single word. If we do not make such assumptions then arguably one can store an infinite amount of data in each word and so every algorithm has constant runtime. Clearly this cannot be true. For our purposes when we want to work with inputs of size $n$ we must have that each word of data can store the value $n$ and so the integers are represented by $c\lg n$ bits for some $c\geq 1$.

This representation in bits can be seen as follows. Since $\lg$ is base $2$ we then have $2^{\lg n}=n$. However note that in machine counting we start at $0$ so if we have $\lg n$ bits in a machine we can count from $0$ to $n-1$. Hence, we require at least one extra bit, that is, $\lg n + 1$ bits. This can also be expresses as $c\lg n$ bits for some $c\geq 1$.

The importance of this calculation becomes more obvious when we deal with recurrences. For example, if we start with an input of size $n$ and our recurrence halves the input size at each iteration,
\begin{equation*}
	T(n) =
	\begin{cases}
		c& \text{if }n=1\\
		T(n/2)& \text{otherwise}
	\end{cases}
\end{equation*}
Then we know that we will need at least $\lg n$ iterations to reach a constant case as,
\begin{equation*}
	T\left(\frac{n}{2\cdot2\cdots2}\right) = T\left(\frac{n}{2^{\lg n}}\right)\approx T(1)
\end{equation*}
Remember, we are simulating counting in a machine which starts from $0$ and hence the $\approx$ above instead of $=$.
